<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects_and_works on Nick Arner</title>
    <link>/projects_and_work/</link>
    <description>Recent content in Projects_and_works on Nick Arner</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="/projects_and_work/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Emulating Touché</title>
      <link>/projects_and_work/emulating_touch%C3%A9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects_and_work/emulating_touch%C3%A9/</guid>
      <description>In 2017, I worked on a project where I built a circuit that emulated the Touché circuit from Disney Research.
I wanted to see if, using the circuit and machine-learning software, I could replicate the results of the Touché paper by training a system to detect how I was touching various plants, or how to use water as an interface.</description>
    </item>
    
    <item>
      <title>O Soli Mio</title>
      <link>/projects_and_work/o_soli_mio/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects_and_work/o_soli_mio/</guid>
      <description>I was of 80 developers worldwide to be accepted into Google&amp;rsquo;s Project Soli Alpha Developer Program and was one of only 14 Alpha Developers to be invited to Google HQ to workshop new ideas regarding potential applications using SOLI. Specifically, my work involved investigating Soli&amp;rsquo;s potential use in new musical instruments. Some of this work was show in in this video presented by ATAP at Google I/O 2016:

This research was published in O Soli Mio: Exploring Millimeter Wave Radar for Musical Interaction, co-written with Francisco Bernardo and Paul Batchelor, at the NIME 2017 Conference in Copenhagen.</description>
    </item>
    
    <item>
      <title>Push-To-Talk Audio Chat App</title>
      <link>/projects_and_work/push_to_talk_audio_chat_app/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects_and_work/push_to_talk_audio_chat_app/</guid>
      <description>Through December 2019 to Feburary 2020, Julie Young and I built a push-to-talk audio chat app. It let users create audio channels that would be broadcast to others in a nearby physical location.
Users could see available nearby channels and join them. Using the push-to-talk interface, they could talk to the channel.
 Creating Audio Channels
We used the OpenTok (now known as the Vonage Video API) SDK for audio channel creation and communciation.</description>
    </item>
    
    <item>
      <title>Whistlr</title>
      <link>/projects_and_work/whistlr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects_and_work/whistlr/</guid>
      <description>with Matt Becker and Tana Green
Whistlr was an app for sharing your contact information with acquaintances, colleagues at a conference, or the person you just met at the coffeeshop.
The app would create your contact profile by pulling in your contact card information from the iOS Contacts App. Once you had done that, you could share your contact card with othter people nearby who had Whistlr open. For security, whenever a contact card was sent, a three-digit code was generated.</description>
    </item>
    
  </channel>
</rss>
